{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-zQZdnbBtPt3"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import torch.nn as nn \n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from tqdm import tqdm, trange\n",
    "import csv \n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    BertConfig,\n",
    "    BertTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from transformers import BertPreTrainedModel, BertModel\n",
    "\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "except ImportError:\n",
    "    from tensorboardX import SummaryWriter\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6tUgw4D1xtg_"
   },
   "outputs": [],
   "source": [
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed_all(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rC-LgL1WxhtH"
   },
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"\n",
    "    A single training/test example for the Yelp dataset.\n",
    "    For examples without an answer, the start and end position are -1.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 stars,\n",
    "                 text,\n",
    "                dense_feats):\n",
    "        self.stars = stars\n",
    "        self.dense_feats = dense_feats\n",
    "        self.text = text\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "\n",
    "    def __repr__(self):\n",
    "        s = \"\"\n",
    "        s += \"stars: %d\" % (self.stars)\n",
    "        s += \", text: %s\" % (\n",
    "            self.text)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "59UoLmBIxk7N"
   },
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_ids, dense_feats):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_ids = label_ids\n",
    "        self.dense_feats = dense_feats\n",
    "\n",
    "\n",
    "def read_examples_from_file(data_dir, mode):\n",
    "    file_path = os.path.join(data_dir, \"{}.csv\".format(mode))\n",
    "\n",
    "    examples = []\n",
    "    with open(file_path, \"r\", encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        for line in reader:\n",
    "            example = InputExample(\n",
    "                stars=int(line[0]),\n",
    "                dense_feats = [float(x) for x in line[2].strip().split()],\n",
    "                text=line[1])\n",
    "            examples.append(example)\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "sPD2_Q6Fxnce"
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_features(\n",
    "    examples,\n",
    "    label_list,\n",
    "    max_seq_length,\n",
    "    tokenizer,\n",
    "    cls_token_at_end=False,\n",
    "    cls_token=\"[CLS]\",\n",
    "    cls_token_segment_id=1,\n",
    "    sep_token=\"[SEP]\",\n",
    "    sep_token_extra=False,\n",
    "    pad_on_left=False,\n",
    "    pad_token=0,\n",
    "    pad_token_segment_id=0,\n",
    "    pad_token_label_id=-100,\n",
    "    sequence_a_segment_id=0,\n",
    "    mask_padding_with_zero=True,\n",
    "):\n",
    "\n",
    "    label_map = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        if ex_index % 10000 == 0:\n",
    "            logger.info(\"Writing example %d of %d\", ex_index, len(examples))\n",
    "\n",
    "        tokens = []\n",
    "        label_ids = []\n",
    "        word = example.text\n",
    "        label = example.stars\n",
    "        dense_feats = example.dense_feats\n",
    "        word_tokens = tokenizer.tokenize(word)\n",
    "        tokens.extend(word_tokens)\n",
    "        # Use the real label id for the first token of the word, and padding ids for the remaining tokens\n",
    "        label_ids.extend([float(label_map[label])])\n",
    "\n",
    "        # Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.\n",
    "        special_tokens_count = 3 if sep_token_extra else 2\n",
    "        if len(tokens) > max_seq_length - special_tokens_count:\n",
    "            tokens = tokens[: (max_seq_length - special_tokens_count)]\n",
    "\n",
    "        tokens += [sep_token]\n",
    "        if sep_token_extra:\n",
    "            # roberta uses an extra separator b/w pairs of sentences\n",
    "            tokens += [sep_token]\n",
    "        segment_ids = [sequence_a_segment_id] * len(tokens)\n",
    "\n",
    "        if cls_token_at_end:\n",
    "            tokens += [cls_token]\n",
    "            segment_ids += [cls_token_segment_id]\n",
    "        else:\n",
    "            tokens = [cls_token] + tokens\n",
    "            segment_ids = [cls_token_segment_id] + segment_ids\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding_length = max_seq_length - len(input_ids)\n",
    "        if pad_on_left:\n",
    "            input_ids = ([pad_token] * padding_length) + input_ids\n",
    "            input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n",
    "            segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n",
    "        else:\n",
    "            input_ids += [pad_token] * padding_length\n",
    "            input_mask += [0 if mask_padding_with_zero else 1] * padding_length\n",
    "            segment_ids += [pad_token_segment_id] * padding_length\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "\n",
    "        if ex_index < 5:\n",
    "            logger.info(\"*** Example ***\")\n",
    "            logger.info(\"tokens: %s\", \" \".join([str(x) for x in tokens]))\n",
    "            logger.info(\"input_ids: %s\", \" \".join([str(x) for x in input_ids]))\n",
    "            logger.info(\"input_mask: %s\", \" \".join([str(x) for x in input_mask]))\n",
    "            logger.info(\"segment_ids: %s\", \" \".join([str(x) for x in segment_ids]))\n",
    "            logger.info(\"label_ids: %s\", \" \".join([str(x) for x in label_ids]))\n",
    "\n",
    "        features.append(\n",
    "            InputFeatures(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_ids=label_ids, dense_feats = dense_feats)\n",
    "        )\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "1vCOiZXbtukI"
   },
   "outputs": [],
   "source": [
    "class BertForSentimentAnalysis(BertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.dense_layer = nn.Linear(config.dense_size + config.hidden_size, 256)\n",
    "        self.dropout2 = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(256, self.num_labels)\n",
    "        # Default regression loss function\n",
    "        self.loss = 'mse'\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def set_loss(self, loss):\n",
    "        self.loss = loss\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        dense_feats=None,\n",
    "    ):\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        pooled_output = torch.cat((pooled_output,dense_feats), dim=1)\n",
    "        pooled_output = self.dense_layer(pooled_output)\n",
    "        pooled_output = self.dropout2(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "\n",
    "        if labels is not None:\n",
    "            # regression\n",
    "            if self.num_labels == 1:\n",
    "                if self.loss == 'mse':\n",
    "                    # Use mean squared loss for regression\n",
    "                    loss_fct = MSELoss()\n",
    "                    loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "                elif self.loss == 'smoothl1':\n",
    "                    # Use smooth l1 loss for regression\n",
    "                    loss_fct = torch.nn.SmoothL1Loss()\n",
    "                    loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "                elif self.loss == 'masked_mse':\n",
    "                    # Use masked mean squared loss for regression\n",
    "                    loss = masked_mse_loss(logits.view(-1), labels.view(-1))\n",
    "                elif self.loss == 'masked_smoothl1':\n",
    "                    # Use masked smooth l1 loss for regression\n",
    "                    loss = masked_smooth_l1_loss(logits.view(-1), labels.view(-1))\n",
    "                else:\n",
    "                    print('Loss function not supported.')\n",
    "\n",
    "            # classification\n",
    "            else:\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs  # (loss), logits, (hidden_states), (attentions)\n",
    "\n",
    "\n",
    "def masked_smooth_l1_loss(input, target):\n",
    "    t = torch.abs(input - target)\n",
    "    smooth_l1 = torch.where(t < 1, 0.5 * t ** 2, t - 0.5)\n",
    "\n",
    "    zeros = torch.zeros_like(smooth_l1)\n",
    "\n",
    "    extreme_target = torch.abs(target - 2)\n",
    "    extreme_input = torch.abs(input - 2)\n",
    "    mask = (extreme_target == 2) * (extreme_input > 2)\n",
    "\n",
    "    return torch.where(mask, zeros, smooth_l1).sum()\n",
    "\n",
    "\n",
    "def masked_mse_loss(input, target):\n",
    "    t = torch.abs(input - target)\n",
    "    mse = t ** 2\n",
    "\n",
    "    zeros = torch.zeros_like(mse)\n",
    "\n",
    "    extreme_target = torch.abs(target - 2)\n",
    "    extreme_input = torch.abs(input - 2)\n",
    "    mask = (extreme_target == 2) * (extreme_input > 2)\n",
    "\n",
    "    return torch.mean(torch.where(mask, zeros, mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "woJOcbOJuF42"
   },
   "outputs": [],
   "source": [
    "def train(args, train_dataset, model, tokenizer, labels, pad_token_label_id):\n",
    "    \"\"\" Train the model \"\"\"\n",
    "    tb_writer = SummaryWriter()\n",
    "\n",
    "    args.train_batch_size = args.per_gpu_train_batch_size\n",
    "    train_sampler = RandomSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)\n",
    "\n",
    "    if args.max_steps > 0:\n",
    "        t_total = args.max_steps\n",
    "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
    "    else:\n",
    "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "\n",
    "    # Prepare optimizer and schedule (linear warmup and decay)\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": args.weight_decay,\n",
    "        },\n",
    "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
    "    )\n",
    "\n",
    "    # Check if saved optimizer or scheduler states exist\n",
    "    if os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\")) and os.path.isfile(\n",
    "        os.path.join(args.model_name_or_path, \"scheduler.pt\")\n",
    "    ):\n",
    "        # Load in optimizer and scheduler states\n",
    "        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n",
    "        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n",
    "\n",
    "    # Train!\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
    "    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n",
    "    logger.info(\n",
    "        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
    "        args.train_batch_size\n",
    "        * args.gradient_accumulation_steps,\n",
    "    )\n",
    "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
    "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "\n",
    "    global_step = 0\n",
    "    epochs_trained = 0\n",
    "    steps_trained_in_current_epoch = 0\n",
    "    # Check if continuing training from a checkpoint\n",
    "    if os.path.exists(args.model_name_or_path):\n",
    "        # set global_step to gobal_step of last saved checkpoint from model path\n",
    "        global_step = int(args.model_name_or_path.split(\"-\")[-1].split(\"/\")[0])\n",
    "        epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n",
    "        steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n",
    "\n",
    "        logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
    "        logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n",
    "        logger.info(\"  Continuing training from global step %d\", global_step)\n",
    "        logger.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n",
    "\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    model.zero_grad()\n",
    "    train_iterator = trange(\n",
    "        epochs_trained, int(args.num_train_epochs), desc=\"Epoch\"\n",
    "    )\n",
    "    set_seed(args)  # Added here for reproducibility\n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "\n",
    "            # Skip past any already trained steps if resuming training\n",
    "            if steps_trained_in_current_epoch > 0:\n",
    "                steps_trained_in_current_epoch -= 1\n",
    "                continue\n",
    "\n",
    "            model.train()\n",
    "            batch = tuple(t.to(args.device) for t in batch)\n",
    "            inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"token_type_ids\": batch[2], \"labels\": batch[3], \"dense_feats\": batch[4]}\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)\n",
    "\n",
    "            if args.gradient_accumulation_steps > 1:\n",
    "                loss = loss / args.gradient_accumulation_steps\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "\n",
    "                scheduler.step()  # Update learning rate schedule\n",
    "                optimizer.step()\n",
    "                model.zero_grad()\n",
    "                global_step += 1\n",
    "\n",
    "                if args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
    "                    # Log metrics\n",
    "                    if (\n",
    "                        args.evaluate_during_training\n",
    "                    ):  # Only evaluate when single GPU otherwise metrics may not average well\n",
    "                        results, _ = evaluate(args, model, tokenizer, labels, pad_token_label_id, mode=\"val\")\n",
    "                        for key, value in results.items():\n",
    "                            tb_writer.add_scalar(\"eval_{}\".format(key), value, global_step)\n",
    "                    tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n",
    "                    tb_writer.add_scalar(\"loss\", (tr_loss - logging_loss) / args.logging_steps, global_step)\n",
    "                    logging_loss = tr_loss\n",
    "\n",
    "                if args.save_steps > 0 and global_step % args.save_steps == 0:\n",
    "                    # Save model checkpoint\n",
    "                    output_dir = os.path.join(args.output_dir, \"checkpoint-{}\".format(global_step))\n",
    "                    if not os.path.exists(output_dir):\n",
    "                        os.makedirs(output_dir)\n",
    "                    model_to_save = (\n",
    "                        model.module if hasattr(model, \"module\") else model\n",
    "                    )  # Take care of distributed/parallel training\n",
    "                    model_to_save.save_pretrained(output_dir)\n",
    "                    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "                    torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
    "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
    "\n",
    "                    torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
    "                    torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
    "                    logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n",
    "\n",
    "            if args.max_steps > 0 and global_step > args.max_steps:\n",
    "                epoch_iterator.close()\n",
    "                break\n",
    "        if args.max_steps > 0 and global_step > args.max_steps:\n",
    "            train_iterator.close()\n",
    "            break\n",
    "\n",
    "    tb_writer.close()\n",
    "\n",
    "    return global_step, tr_loss / global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "-6PiYXk8uL1v"
   },
   "outputs": [],
   "source": [
    "def evaluate(args, model, tokenizer, labels, pad_token_label_id, mode, prefix=\"\"):\n",
    "    eval_dataset = load_and_cache_examples(args, tokenizer, labels, pad_token_label_id, mode=mode)\n",
    "\n",
    "    args.eval_batch_size = args.per_gpu_eval_batch_size\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation %s *****\", prefix)\n",
    "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "\n",
    "    model.eval()\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        batch = tuple(t.to(args.device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"token_type_ids\": batch[2], \"labels\": batch[3], \"dense_feats\": batch[4]}\n",
    "            outputs = model(**inputs)\n",
    "            tmp_eval_loss, logits = outputs[:2]\n",
    "            eval_loss += tmp_eval_loss\n",
    "        nb_eval_steps += 1\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    if args.regression:\n",
    "        preds = np.squeeze(preds)\n",
    "        for i in range(len(preds)):\n",
    "            if preds[i] <= 0:\n",
    "                preds[i] = 0\n",
    "            elif preds[i] >= 4:\n",
    "                preds[i] = 4\n",
    "    else:\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "\n",
    "    out_label_ids = out_label_ids.flatten()\n",
    "\n",
    "    accuracy = accuracy_score([round(x) for x in out_label_ids], [round(x) for x in preds])\n",
    "    mae = mean_absolute_error(out_label_ids, preds)\n",
    "    mse = mean_squared_error(out_label_ids, preds)\n",
    "\n",
    "    results = {\n",
    "        \"loss\": eval_loss,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"mean_absolute_error\": mae,\n",
    "        \"mean_squared_error\": mse,\n",
    "    }\n",
    "\n",
    "    logger.info(\"***** Eval results %s *****\", prefix)\n",
    "    for key in sorted(results.keys()):\n",
    "        logger.info(\"  %s = %s\", key, str(results[key]))\n",
    "\n",
    "    return results, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "NNJOTJIDuUSx"
   },
   "outputs": [],
   "source": [
    "def load_and_cache_examples(args, tokenizer, labels, pad_token_label_id, mode):\n",
    "    # Load data features from cache or dataset file\n",
    "    cached_features_file = os.path.join(\n",
    "        args.data_dir,\n",
    "        \"cached_{}_{}_{}\".format(\n",
    "            mode, list(filter(None, args.model_name_or_path.split(\"/\"))).pop(), str(args.max_seq_length)\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    if os.path.exists(cached_features_file) and not args.overwrite_cache:\n",
    "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
    "        features = torch.load(cached_features_file)\n",
    "    else:\n",
    "        logger.info(\"Creating features from dataset file at %s\", args.data_dir)\n",
    "        examples = read_examples_from_file(args.data_dir, mode)\n",
    "        features = convert_examples_to_features(\n",
    "            examples,\n",
    "            labels,\n",
    "            args.max_seq_length,\n",
    "            tokenizer,\n",
    "            cls_token_at_end=False,\n",
    "            cls_token=tokenizer.cls_token,\n",
    "            cls_token_segment_id=0,\n",
    "            sep_token=tokenizer.sep_token,\n",
    "            sep_token_extra=False,\n",
    "            pad_on_left=False,\n",
    "            pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
    "            pad_token_segment_id=0,\n",
    "            pad_token_label_id=pad_token_label_id,\n",
    "        )\n",
    "        logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
    "        torch.save(features, cached_features_file)\n",
    "\n",
    "    # Convert to Tensors and build dataset\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    all_dense_feats = torch.tensor([f.dense_feats for f in features], dtype=torch.float)\n",
    "    if args.regression:\n",
    "        all_label_ids = torch.tensor([f.label_ids for f in features], dtype=torch.float)\n",
    "    else:\n",
    "        all_label_ids = torch.tensor([f.label_ids for f in features], dtype=torch.long)\n",
    "    dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids, all_dense_feats)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "OFX0fA_iwAyu"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "def get_args(data_dir, model_name_or_path=None, output_dir=\"./output\", num_train_epochs=3.0, overwrite_output_dir=False, do_train=True):\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Required parameters\n",
    "    parser.add_argument(\n",
    "        \"--data_dir\",\n",
    "        default=None,\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"The input data dir. Should contain the training files for the Yelp-5 Sentiment Analysis task.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model_name_or_path\",\n",
    "        default=None,\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Path to pre-trained model or shortcut name.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output_dir\",\n",
    "        default=None,\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"The output directory where the model predictions and checkpoints will be written.\",\n",
    "    )\n",
    "\n",
    "    # Other parameters\n",
    "    parser.add_argument(\n",
    "        \"--config_name\", default=\"\", type=str, help=\"Pre-trained config name or path if not the same as model_name\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--tokenizer_name\",\n",
    "        default=\"\",\n",
    "        type=str,\n",
    "        help=\"Pre-trained tokenizer name or path if not the same as model_name\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--cache_dir\",\n",
    "        default=\"\",\n",
    "        type=str,\n",
    "        help=\"Where do you want to store the pre-trained models downloaded from s3\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_seq_length\",\n",
    "        default=128,\n",
    "        type=int,\n",
    "        help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "        \"than this will be truncated, sequences shorter will be padded.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--evaluate_during_training\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Whether to run evaluation during training at each logging step.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--do_train\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Whether to train the model or simply evaluate from output directory.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--do_lower_case\", action=\"store_true\", help=\"Set this flag if you are using an uncased model.\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\"--per_gpu_train_batch_size\", default=8, type=int, help=\"Batch size per GPU/CPU for training.\")\n",
    "    parser.add_argument(\n",
    "        \"--per_gpu_eval_batch_size\", default=8, type=int, help=\"Batch size per GPU/CPU for evaluation.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gradient_accumulation_steps\",\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
    "    )\n",
    "    parser.add_argument(\"--learning_rate\", default=5e-5, type=float, help=\"The initial learning rate for Adam.\")\n",
    "    parser.add_argument(\"--weight_decay\", default=0.0, type=float, help=\"Weight decay if we apply some.\")\n",
    "    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n",
    "    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n",
    "    parser.add_argument(\n",
    "        \"--num_train_epochs\", default=3.0, type=float, help=\"Total number of training epochs to perform.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_steps\",\n",
    "        default=-1,\n",
    "        type=int,\n",
    "        help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\",\n",
    "    )\n",
    "    parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\")\n",
    "\n",
    "    parser.add_argument(\"--logging_steps\", type=int, default=500, help=\"Log every X updates steps.\")\n",
    "    parser.add_argument(\"--save_steps\", type=int, default=5000, help=\"Save checkpoint every X updates steps.\")\n",
    "    parser.add_argument(\n",
    "        \"--eval_all_checkpoints\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\",\n",
    "    )\n",
    "    parser.add_argument(\"--no_cuda\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n",
    "    parser.add_argument(\n",
    "        \"--overwrite_output_dir\", action=\"store_true\", help=\"Overwrite the content of the output directory\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--overwrite_cache\", action=\"store_true\", help=\"Overwrite the cached training and evaluation sets\"\n",
    "    )\n",
    "    parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed for initialization\")\n",
    "    parser.add_argument(\"--regression\", action=\"store_true\", help=\"Perform regression instead of classification\")\n",
    "    parser.add_argument(\n",
    "        \"--loss\", default=\"mse\", type=str, help=\"Use the specified loss function for regression\"\n",
    "    )\n",
    "    args = parser.parse_args((\"--data_dir %s --output_dir %s --model_name_or_path %s --num_train_epochs %d\"%(data_dir, output_dir, model_name_or_path, num_train_epochs)).split())\n",
    "    args.overwrite_output_dir = overwrite_output_dir\n",
    "    args.do_train = do_train\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "3dBrbtORuUpA"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    args = get_args(\"./binary_bert_data\", output_dir=\"./output_dense_cat\",model_name_or_path=\"bert-base-uncased\", num_train_epochs=3.0, overwrite_output_dir=True, do_train=True)\n",
    "    if (\n",
    "        os.path.exists(args.output_dir)\n",
    "        and os.listdir(args.output_dir)\n",
    "        # and args.do_train\n",
    "        and not args.overwrite_output_dir\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n",
    "                args.output_dir\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Setup CUDA, GPU or CPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "    args.device = device\n",
    "\n",
    "    # Setup logging\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    "    )\n",
    "\n",
    "    # Set seed\n",
    "    set_seed(args)\n",
    "    labels = [0.0, 1.0]\n",
    "    if args.regression:\n",
    "        num_labels = 1\n",
    "    else:\n",
    "        num_labels = len(labels)\n",
    "    # Use cross entropy ignore index as padding label id so that only real label ids contribute to the loss later\n",
    "    pad_token_label_id = CrossEntropyLoss().ignore_index\n",
    "\n",
    "    # Load pretrained model and tokenizer\n",
    "    config_class = BertConfig\n",
    "    model_class = BertForSentimentAnalysis\n",
    "    tokenizer_class = BertTokenizer\n",
    "    config = config_class.from_pretrained(\n",
    "        args.config_name if args.config_name else args.model_name_or_path,\n",
    "        num_labels=num_labels,\n",
    "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
    "    )\n",
    "    config.dense_size = 209\n",
    "    tokenizer = tokenizer_class.from_pretrained(\n",
    "        args.tokenizer_name if args.tokenizer_name else args.model_name_or_path,\n",
    "        do_lower_case=args.do_lower_case,\n",
    "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
    "    )\n",
    "    model = model_class.from_pretrained(\n",
    "        args.model_name_or_path,\n",
    "        from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
    "        config=config,\n",
    "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
    "    )\n",
    "\n",
    "    model.set_loss(args.loss)\n",
    "\n",
    "    model.to(args.device)\n",
    "\n",
    "    logger.info(\"Training/evaluation parameters %s\", args)\n",
    "\n",
    "    # Training\n",
    "    if args.do_train:\n",
    "      train_dataset = load_and_cache_examples(args, tokenizer, labels, pad_token_label_id, mode=\"train\")\n",
    "      global_step, tr_loss = train(args, train_dataset, model, tokenizer, labels, pad_token_label_id)\n",
    "      logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
    "\n",
    "    # Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "      if not os.path.exists(args.output_dir):\n",
    "          os.makedirs(args.output_dir)\n",
    "\n",
    "      logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
    "      # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "      # They can then be reloaded using `from_pretrained()`\n",
    "      model_to_save = (\n",
    "          model.module if hasattr(model, \"module\") else model\n",
    "      )  # Take care of distributed/parallel training\n",
    "      model_to_save.save_pretrained(args.output_dir)\n",
    "      tokenizer.save_pretrained(args.output_dir)\n",
    "\n",
    "      # Good practice: save your training arguments together with the trained model\n",
    "      torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n",
    "    # Testing\n",
    "    else:\n",
    "      args.output_dir = args.model_name_or_path\n",
    "    tokenizer = tokenizer_class.from_pretrained(args.output_dir, do_lower_case=args.do_lower_case)\n",
    "    model = model_class.from_pretrained(args.output_dir)\n",
    "    model.to(args.device)\n",
    "    result, predictions = evaluate(args, model, tokenizer, labels, pad_token_label_id, mode=\"test\")\n",
    "    # Save results\n",
    "    output_test_results_file = os.path.join(args.output_dir, \"test_results.txt\")\n",
    "    with open(output_test_results_file, \"w\") as writer:\n",
    "        for key in sorted(result.keys()):\n",
    "            writer.write(\"{} = {}\\n\".format(key, str(result[key])))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e66eb9869d7f40ba926fb9dd54bef61a",
      "a43944d15aef4f6eb1d9442046304508",
      "8a63c282ff954a539699452b5151a98e",
      "9fa87257455049879c797ca95acad14b",
      "4dfb735579d949e6a405d44b0e88d5c0",
      "79a18185ca374d6f9a10923613ad26dc",
      "1fc5ae46b9094a8f93f27e4b1bc8442e",
      "2c26cf1649124b0baf50c771f619fd76",
      "80c3ad8fa92948c6a9af05af3ec55c33",
      "9cabf8b62af84e8eab65422163ebca19",
      "e2a9bca1e5de46789307d8b2f3301247",
      "dea3e998a0d14e83907b86def17a726f",
      "4fdd083779714592a89bc74047cdadd5",
      "25b9af2cc1ba48f8b76ef652b18b7297",
      "8d905f23fc2e4849b5f6f5c1fa7543a7",
      "5b12a2846035414d9b4e1d55db627e99",
      "e0a66c659d604fe388cad2215e0ce011",
      "b2fc4394642141f79861657af1c2915e",
      "e0a2be1dc60b4ce1b6e59d02cbd0f214",
      "d55f71b654174839bd0a527c82e12cb7",
      "e7060159bdfa4bce9e5149643186b448",
      "cf4319b37f074193a84f36ee1deacb0b",
      "60c95bbb4f0948288016eee1f8d47b4f",
      "aa1f1758b46a4bcbbba71b2e9a508660",
      "60284e6c8d7d47b6a125ca9f60503816",
      "48511d4fb37f4b0192be150a1c7b84f1",
      "aba0f00b3db54eb1926853aa7df11ac7",
      "1f8b670895504138b2e9a56050328444",
      "d990f46372604f29a76f968b8195870b",
      "9626f8abe6cc4c22b732312ce8083ce2",
      "a395c797f6f043acb50b905ba67db583",
      "5d28ba320b5e40019955361946539ad0",
      "dc0cca8b8de44b83bdec79da04bc6253",
      "9e60609fc1244c0c8bf6b1d320281f9e",
      "94c84c9c391240a1912cf07784d49337",
      "5ca0a54308424989a2171fcde6c83354",
      "bc29964e8cd647bca77f92551ac40ecf",
      "bee625fd31fb436586ef5132fd92107c",
      "ceab5a487d25481f9fdc754927ef5300",
      "fce4c7ba12c3405e8f9d781382a3ac8c",
      "c964ae9ed8144160976207073cf88e28",
      "24413a40c04e4d939a9e4ebfd2c75b4c",
      "a645e0f2f57b48bd80dc9516ec97f489",
      "b0a1cbb9af474b44a6aaba57ce6aa0c8"
     ]
    },
    "id": "2oDLIhgqyZd2",
    "outputId": "ead2c804-5277-4c2c-b78d-5d3c7cf6304f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSentimentAnalysis: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSentimentAnalysis from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSentimentAnalysis from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSentimentAnalysis were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['dense_layer.bias', 'classifier.weight', 'classifier.bias', 'dense_layer.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "12/07/2021 04:16:58 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='./binary_bert_data', device=device(type='cuda'), do_lower_case=False, do_train=True, eval_all_checkpoints=False, evaluate_during_training=False, gradient_accumulation_steps=1, learning_rate=5e-05, logging_steps=500, loss='mse', max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', no_cuda=False, num_train_epochs=3.0, output_dir='./output_dense_cat', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, regression=False, save_steps=5000, seed=42, tokenizer_name='', warmup_steps=0, weight_decay=0.0)\n",
      "12/07/2021 04:16:58 - INFO - __main__ -   Creating features from dataset file at ./binary_bert_data\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   Writing example 0 of 31188\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   *** Example ***\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   tokens: [CLS] [UNK] love having breakfast here . [UNK] have always had good service . [UNK] waitress ##es are friendly and keep our drinks full . [UNK] food is hot and good . [UNK] prices are great for the amount of food you get . [UNK] ' ve had the chocolate pie as well and it ' s wonderful . [SEP]\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   input_ids: 101 100 2293 2383 6350 2182 1012 100 2031 2467 2018 2204 2326 1012 100 13877 2229 2024 5379 1998 2562 2256 8974 2440 1012 100 2833 2003 2980 1998 2204 1012 100 7597 2024 2307 2005 1996 3815 1997 2833 2017 2131 1012 100 1005 2310 2018 1996 7967 11345 2004 2092 1998 2009 1005 1055 6919 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   label_ids: 1.0\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   *** Example ***\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   tokens: [CLS] [UNK] sure what the concept is at [UNK] . [UNK] put it simply , [UNK] found my dinner experience to be confused . [UNK] is odd wall ##paper with an [UNK] theme while the menu contained everything from barbecue to na ##cho ##s to egg rolls to g ##yr ##os . [UNK] was necessarily bad , but as [UNK] said before , confused . [UNK] atmosphere is just as strange for a dining establishment which calls itself a bis ##tro . . . there was nothing [UNK] or \" bis ##tro - y \" about it . [UNK] hate to give a negative review to a local eater ##y here in [UNK] , as small business is what keeps [UNK] so vibrant ! [UNK] [UNK] however [SEP]\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   input_ids: 101 100 2469 2054 1996 4145 2003 2012 100 1012 100 2404 2009 3432 1010 100 2179 2026 4596 3325 2000 2022 5457 1012 100 2003 5976 2813 23298 2007 2019 100 4323 2096 1996 12183 4838 2673 2013 26375 2000 6583 9905 2015 2000 8288 9372 2000 1043 12541 2891 1012 100 2001 9352 2919 1010 2021 2004 100 2056 2077 1010 5457 1012 100 7224 2003 2074 2004 4326 2005 1037 7759 5069 2029 4455 2993 1037 20377 13181 1012 1012 1012 2045 2001 2498 100 2030 1000 20377 13181 1011 1061 1000 2055 2009 1012 100 5223 2000 2507 1037 4997 3319 2000 1037 2334 28496 2100 2182 1999 100 1010 2004 2235 2449 2003 2054 7906 100 2061 17026 999 100 100 2174 102\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   label_ids: 0.0\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   *** Example ***\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   tokens: [CLS] [UNK] the breakfast ta ##cos ! [UNK] place is not cheap but you ' re getting what you pay for . [UNK] - notch quality . [SEP]\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   input_ids: 101 100 1996 6350 11937 13186 999 100 2173 2003 2025 10036 2021 2017 1005 2128 2893 2054 2017 3477 2005 1012 100 1011 18624 3737 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   label_ids: 1.0\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   *** Example ***\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   tokens: [CLS] [UNK] to [UNK] today because my friend was craving a burger . [UNK] had never din ##ed here before , but she had and suggested it . [UNK] was thoroughly impressed . [UNK] had the bison burger which was to die for , [UNK] had a bite and instantly wanted another . [UNK] ordered the [UNK] and it was loaded with bacon and flavor . [UNK] had some minor issues with it , first being that there was just a little too much ai ##oli on the bread and second that the fried tomato was a red tomato and not a green tomato . [UNK] just found the texture of the tomato una ##ppet ##izing . [UNK] also enjoyed their bloody mary and they have a [SEP]\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   input_ids: 101 100 2000 100 2651 2138 2026 2767 2001 26369 1037 15890 1012 100 2018 2196 11586 2098 2182 2077 1010 2021 2016 2018 1998 4081 2009 1012 100 2001 12246 7622 1012 100 2018 1996 22285 15890 2029 2001 2000 3280 2005 1010 100 2018 1037 6805 1998 6880 2359 2178 1012 100 3641 1996 100 1998 2009 2001 8209 2007 11611 1998 14894 1012 100 2018 2070 3576 3314 2007 2009 1010 2034 2108 2008 2045 2001 2074 1037 2210 2205 2172 9932 10893 2006 1996 7852 1998 2117 2008 1996 13017 20856 2001 1037 2417 20856 1998 2025 1037 2665 20856 1012 100 2074 2179 1996 14902 1997 1996 20856 14477 29519 6026 1012 100 2036 5632 2037 6703 2984 1998 2027 2031 1037 102\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   label_ids: 1.0\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   *** Example ***\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   tokens: [CLS] [UNK] best egg rolls [UNK] ' ve ever had . [UNK] rest of the food is very good too . [UNK] version of sweet and sour shrimp ( no bread ##ing on shrimp ) was great . [UNK] is great and prices are reasonable . [SEP]\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   input_ids: 101 100 2190 8288 9372 100 1005 2310 2412 2018 1012 100 2717 1997 1996 2833 2003 2200 2204 2205 1012 100 2544 1997 4086 1998 14768 20130 1006 2053 7852 2075 2006 20130 1007 2001 2307 1012 100 2003 2307 1998 7597 2024 9608 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2021 04:17:00 - INFO - __main__ -   label_ids: 1.0\n",
      "12/07/2021 04:17:17 - INFO - __main__ -   Writing example 10000 of 31188\n",
      "12/07/2021 04:17:33 - INFO - __main__ -   Writing example 20000 of 31188\n",
      "12/07/2021 04:17:50 - INFO - __main__ -   Writing example 30000 of 31188\n",
      "12/07/2021 04:17:52 - INFO - __main__ -   Saving features into cached file ./binary_bert_data/cached_train_bert-base-uncased_128\n",
      "12/07/2021 04:17:57 - INFO - __main__ -   ***** Running training *****\n",
      "12/07/2021 04:17:57 - INFO - __main__ -     Num examples = 31188\n",
      "12/07/2021 04:17:57 - INFO - __main__ -     Num Epochs = 3\n",
      "12/07/2021 04:17:57 - INFO - __main__ -     Instantaneous batch size per GPU = 8\n",
      "12/07/2021 04:17:57 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "12/07/2021 04:17:57 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "12/07/2021 04:17:57 - INFO - __main__ -     Total optimization steps = 11697\n",
      "Epoch:   0%|                                                                                                                                                                          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98979c8214aa49fc8758d2af3683e259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3899 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "Epoch:  33%|█████████████████████████████████████████████████████▋                                                                                                           | 1/3 [14:32<29:04, 872.26s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19215e6dd1b24b8b9d6770c11fe48c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3899 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/07/2021 04:36:31 - INFO - __main__ -   Saving model checkpoint to ./output_dense_cat/checkpoint-5000\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "12/07/2021 04:36:32 - INFO - __main__ -   Saving optimizer and scheduler states to ./output_dense_cat/checkpoint-5000\n",
      "Epoch:  67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                     | 2/3 [28:41<14:18, 858.79s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "465fe2a701e649e0842658d079c2d378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3899 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/07/2021 04:54:34 - INFO - __main__ -   Saving model checkpoint to ./output_dense_cat/checkpoint-10000\n",
      "12/07/2021 04:54:36 - INFO - __main__ -   Saving optimizer and scheduler states to ./output_dense_cat/checkpoint-10000\n",
      "Epoch: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [42:46<00:00, 855.37s/it]\n",
      "12/07/2021 05:00:43 - INFO - __main__ -    global_step = 11697, average loss = 0.30052986737164566\n",
      "12/07/2021 05:00:43 - INFO - __main__ -   Saving model checkpoint to ./output_dense_cat\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   Creating features from dataset file at ./binary_bert_data\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   Writing example 0 of 5504\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   *** Example ***\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   tokens: [CLS] [UNK] , it is a sad state of affairs when [UNK] walk out of this restaurant and say to my husband , \" [UNK] that service sucked , \" and the people who walked out next to us said , \" we agree . \" [UNK] greeting at the counter , clerk didn ' t understand what pin ##ot noir was , only included one piece of pizza in order when [UNK] ordered two and then , stated that only one piece of pizza was available and we were to wait . [UNK] wait my poor husband did . [UNK] piece of supreme pizza was given away at the drive through window . [UNK] waiting 10 min ##s and eating my own pizza , [UNK] finally [SEP]\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   input_ids: 101 100 1010 2009 2003 1037 6517 2110 1997 3821 2043 100 3328 2041 1997 2023 4825 1998 2360 2000 2026 3129 1010 1000 100 2008 2326 8631 1010 1000 1998 1996 2111 2040 2939 2041 2279 2000 2149 2056 1010 1000 2057 5993 1012 1000 100 14806 2012 1996 4675 1010 7805 2134 1005 1056 3305 2054 9231 4140 15587 2001 1010 2069 2443 2028 3538 1997 10733 1999 2344 2043 100 3641 2048 1998 2059 1010 3090 2008 2069 2028 3538 1997 10733 2001 2800 1998 2057 2020 2000 3524 1012 100 3524 2026 3532 3129 2106 1012 100 3538 1997 4259 10733 2001 2445 2185 2012 1996 3298 2083 3332 1012 100 3403 2184 8117 2015 1998 5983 2026 2219 10733 1010 100 2633 102\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   label_ids: 0.0\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   *** Example ***\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   tokens: [CLS] [UNK] ! ! ! ! [UNK] and total [UNK] . [UNK] crashing into each other , food falling on the floor , drinks spilled constantly . [UNK] food was good but the place was [UNK] managed or better yet completely [UNK] . [UNK] thanks not again . [UNK] the zu ##cchi ##ni pancakes and they were good experience was awful . [SEP]\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   input_ids: 101 100 999 999 999 999 100 1998 2561 100 1012 100 12894 2046 2169 2060 1010 2833 4634 2006 1996 2723 1010 8974 13439 7887 1012 100 2833 2001 2204 2021 1996 2173 2001 100 3266 2030 2488 2664 3294 100 1012 100 4283 2025 2153 1012 100 1996 16950 25955 3490 28470 1998 2027 2020 2204 3325 2001 9643 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   label_ids: 0.0\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   *** Example ***\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   tokens: [CLS] [UNK] food is an ok deal ( pretty good burger ##s and the chicken pot pie is surprisingly good ) for about $ 10 a meal . [UNK] have a pretty big menu , which can be nice for groups . [UNK] is also pretty good - not bad but just above average . [UNK] like the po ##uti ##ne are a great addition to the menu and [UNK] ' s food scene . [UNK] : you have to order food to sit in the beer garden ( you ' d think ordering beer would be the requirement . . . ) . [UNK] is hit ( but a few times , [UNK] ' ve had a miss , sometimes it is flat or stale ) [SEP]\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   input_ids: 101 100 2833 2003 2019 7929 3066 1006 3492 2204 15890 2015 1998 1996 7975 8962 11345 2003 10889 2204 1007 2005 2055 1002 2184 1037 7954 1012 100 2031 1037 3492 2502 12183 1010 2029 2064 2022 3835 2005 2967 1012 100 2003 2036 3492 2204 1011 2025 2919 2021 2074 2682 2779 1012 100 2066 1996 13433 21823 2638 2024 1037 2307 2804 2000 1996 12183 1998 100 1005 1055 2833 3496 1012 100 1024 2017 2031 2000 2344 2833 2000 4133 1999 1996 5404 3871 1006 2017 1005 1040 2228 13063 5404 2052 2022 1996 9095 1012 1012 1012 1007 1012 100 2003 2718 1006 2021 1037 2261 2335 1010 100 1005 2310 2018 1037 3335 1010 2823 2009 2003 4257 2030 26729 1007 102\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   label_ids: 1.0\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   *** Example ***\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   tokens: [CLS] [UNK] just happened upon this place when looking , on ye ##lp , of course , for a lunch spot when driving through [UNK] ! [UNK] is right [UNK] the runway with a wall of windows so you can watch the planes come and go ; my kids absolutely [UNK] this ! [UNK] even got to see a group of [UNK] - force jets take off from the runway right in front of us . [UNK] that is not enough , the food was really good too ! [UNK] down side is that it is a small restaurant that looks like it is consistently in high demand , but definitely worth the wait . [SEP]\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   input_ids: 101 100 2074 3047 2588 2023 2173 2043 2559 1010 2006 6300 14277 1010 1997 2607 1010 2005 1037 6265 3962 2043 4439 2083 100 999 100 2003 2157 100 1996 9271 2007 1037 2813 1997 3645 2061 2017 2064 3422 1996 9738 2272 1998 2175 1025 2026 4268 7078 100 2023 999 100 2130 2288 2000 2156 1037 2177 1997 100 1011 2486 9924 2202 2125 2013 1996 9271 2157 1999 2392 1997 2149 1012 100 2008 2003 2025 2438 1010 1996 2833 2001 2428 2204 2205 999 100 2091 2217 2003 2008 2009 2003 1037 2235 4825 2008 3504 2066 2009 2003 10862 1999 2152 5157 1010 2021 5791 4276 1996 3524 1012 102 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   label_ids: 1.0\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   *** Example ***\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   tokens: [CLS] [UNK] a rare sunshine - y [UNK] day , [UNK] took a seat in a sun ##beam at the counter of [UNK] [UNK] . [UNK] store was filled with community spirit . [UNK] dad and his little boy sat next to me while he got his son a cookie for breakfast . [UNK] a dad ! [UNK] of many generations were meeting up for breakfast and coffee . [UNK] is a nearby parking lot , but this spot sees plenty of foot and bicycle traffic . [UNK] ordered a cr ##ois ##sant breakfast sandwich with the sausage on the side in case it was too greasy or [UNK] didn ' t like it . [UNK] server was friendly and non - int ##rus ##ive , keeping [SEP]\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   input_ids: 101 100 1037 4678 9609 1011 1061 100 2154 1010 100 2165 1037 2835 1999 1037 3103 28302 2012 1996 4675 1997 100 100 1012 100 3573 2001 3561 2007 2451 4382 1012 100 3611 1998 2010 2210 2879 2938 2279 2000 2033 2096 2002 2288 2010 2365 1037 17387 2005 6350 1012 100 1037 3611 999 100 1997 2116 8213 2020 3116 2039 2005 6350 1998 4157 1012 100 2003 1037 3518 5581 2843 1010 2021 2023 3962 5927 7564 1997 3329 1998 10165 4026 1012 100 3641 1037 13675 10054 22341 6350 11642 2007 1996 24165 2006 1996 2217 1999 2553 2009 2001 2205 26484 2030 100 2134 1005 1056 2066 2009 1012 100 8241 2001 5379 1998 2512 1011 20014 7946 3512 1010 4363 102\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2021 05:00:46 - INFO - __main__ -   label_ids: 1.0\n",
      "12/07/2021 05:00:55 - INFO - __main__ -   Saving features into cached file ./binary_bert_data/cached_test_bert-base-uncased_128\n",
      "12/07/2021 05:00:56 - INFO - __main__ -   ***** Running evaluation  *****\n",
      "12/07/2021 05:00:56 - INFO - __main__ -     Num examples = 5504\n",
      "12/07/2021 05:00:56 - INFO - __main__ -     Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7a6c3e0bc941c4854cb1aee7947d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/07/2021 05:01:43 - INFO - __main__ -   ***** Eval results  *****\n",
      "12/07/2021 05:01:43 - INFO - __main__ -     accuracy = 0.8746366279069767\n",
      "12/07/2021 05:01:43 - INFO - __main__ -     loss = tensor(0.5215, device='cuda:0')\n",
      "12/07/2021 05:01:43 - INFO - __main__ -     mean_absolute_error = 0.12536337209302326\n",
      "12/07/2021 05:01:43 - INFO - __main__ -     mean_squared_error = 0.12536337209302326\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "preds = main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT-Text-Classification",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p37)",
   "language": "python",
   "name": "conda_pytorch_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1f8b670895504138b2e9a56050328444": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1fc5ae46b9094a8f93f27e4b1bc8442e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24413a40c04e4d939a9e4ebfd2c75b4c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25b9af2cc1ba48f8b76ef652b18b7297": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2fc4394642141f79861657af1c2915e",
      "placeholder": "​",
      "style": "IPY_MODEL_e0a66c659d604fe388cad2215e0ce011",
      "value": "Iteration: 100%"
     }
    },
    "2c26cf1649124b0baf50c771f619fd76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "48511d4fb37f4b0192be150a1c7b84f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a395c797f6f043acb50b905ba67db583",
      "max": 3899,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9626f8abe6cc4c22b732312ce8083ce2",
      "value": 3899
     }
    },
    "4dfb735579d949e6a405d44b0e88d5c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2a9bca1e5de46789307d8b2f3301247",
      "placeholder": "​",
      "style": "IPY_MODEL_9cabf8b62af84e8eab65422163ebca19",
      "value": " 3899/3899 [26:32&lt;00:00,  2.77it/s]"
     }
    },
    "4fdd083779714592a89bc74047cdadd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b12a2846035414d9b4e1d55db627e99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf4319b37f074193a84f36ee1deacb0b",
      "placeholder": "​",
      "style": "IPY_MODEL_e7060159bdfa4bce9e5149643186b448",
      "value": " 3899/3899 [26:34&lt;00:00,  2.79it/s]"
     }
    },
    "5ca0a54308424989a2171fcde6c83354": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fce4c7ba12c3405e8f9d781382a3ac8c",
      "placeholder": "​",
      "style": "IPY_MODEL_ceab5a487d25481f9fdc754927ef5300",
      "value": "Evaluating: 100%"
     }
    },
    "5d28ba320b5e40019955361946539ad0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "60284e6c8d7d47b6a125ca9f60503816": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d990f46372604f29a76f968b8195870b",
      "placeholder": "​",
      "style": "IPY_MODEL_1f8b670895504138b2e9a56050328444",
      "value": "Iteration: 100%"
     }
    },
    "60c95bbb4f0948288016eee1f8d47b4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_60284e6c8d7d47b6a125ca9f60503816",
       "IPY_MODEL_48511d4fb37f4b0192be150a1c7b84f1",
       "IPY_MODEL_aba0f00b3db54eb1926853aa7df11ac7"
      ],
      "layout": "IPY_MODEL_aa1f1758b46a4bcbbba71b2e9a508660"
     }
    },
    "79a18185ca374d6f9a10923613ad26dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "80c3ad8fa92948c6a9af05af3ec55c33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a63c282ff954a539699452b5151a98e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fc5ae46b9094a8f93f27e4b1bc8442e",
      "placeholder": "​",
      "style": "IPY_MODEL_79a18185ca374d6f9a10923613ad26dc",
      "value": "Iteration: 100%"
     }
    },
    "8d905f23fc2e4849b5f6f5c1fa7543a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d55f71b654174839bd0a527c82e12cb7",
      "max": 3899,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e0a2be1dc60b4ce1b6e59d02cbd0f214",
      "value": 3899
     }
    },
    "94c84c9c391240a1912cf07784d49337": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9626f8abe6cc4c22b732312ce8083ce2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9cabf8b62af84e8eab65422163ebca19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e60609fc1244c0c8bf6b1d320281f9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5ca0a54308424989a2171fcde6c83354",
       "IPY_MODEL_bc29964e8cd647bca77f92551ac40ecf",
       "IPY_MODEL_bee625fd31fb436586ef5132fd92107c"
      ],
      "layout": "IPY_MODEL_94c84c9c391240a1912cf07784d49337"
     }
    },
    "9fa87257455049879c797ca95acad14b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_80c3ad8fa92948c6a9af05af3ec55c33",
      "max": 3899,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2c26cf1649124b0baf50c771f619fd76",
      "value": 3899
     }
    },
    "a395c797f6f043acb50b905ba67db583": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a43944d15aef4f6eb1d9442046304508": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a645e0f2f57b48bd80dc9516ec97f489": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa1f1758b46a4bcbbba71b2e9a508660": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aba0f00b3db54eb1926853aa7df11ac7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc0cca8b8de44b83bdec79da04bc6253",
      "placeholder": "​",
      "style": "IPY_MODEL_5d28ba320b5e40019955361946539ad0",
      "value": " 3899/3899 [26:35&lt;00:00,  2.78it/s]"
     }
    },
    "b0a1cbb9af474b44a6aaba57ce6aa0c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2fc4394642141f79861657af1c2915e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc29964e8cd647bca77f92551ac40ecf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24413a40c04e4d939a9e4ebfd2c75b4c",
      "max": 688,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c964ae9ed8144160976207073cf88e28",
      "value": 688
     }
    },
    "bee625fd31fb436586ef5132fd92107c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0a1cbb9af474b44a6aaba57ce6aa0c8",
      "placeholder": "​",
      "style": "IPY_MODEL_a645e0f2f57b48bd80dc9516ec97f489",
      "value": " 688/688 [01:21&lt;00:00,  8.46it/s]"
     }
    },
    "c964ae9ed8144160976207073cf88e28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ceab5a487d25481f9fdc754927ef5300": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf4319b37f074193a84f36ee1deacb0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d55f71b654174839bd0a527c82e12cb7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d990f46372604f29a76f968b8195870b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc0cca8b8de44b83bdec79da04bc6253": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dea3e998a0d14e83907b86def17a726f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_25b9af2cc1ba48f8b76ef652b18b7297",
       "IPY_MODEL_8d905f23fc2e4849b5f6f5c1fa7543a7",
       "IPY_MODEL_5b12a2846035414d9b4e1d55db627e99"
      ],
      "layout": "IPY_MODEL_4fdd083779714592a89bc74047cdadd5"
     }
    },
    "e0a2be1dc60b4ce1b6e59d02cbd0f214": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e0a66c659d604fe388cad2215e0ce011": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e2a9bca1e5de46789307d8b2f3301247": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e66eb9869d7f40ba926fb9dd54bef61a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8a63c282ff954a539699452b5151a98e",
       "IPY_MODEL_9fa87257455049879c797ca95acad14b",
       "IPY_MODEL_4dfb735579d949e6a405d44b0e88d5c0"
      ],
      "layout": "IPY_MODEL_a43944d15aef4f6eb1d9442046304508"
     }
    },
    "e7060159bdfa4bce9e5149643186b448": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fce4c7ba12c3405e8f9d781382a3ac8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
